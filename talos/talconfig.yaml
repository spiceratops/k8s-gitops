---
clusterName: &cluster k8s

clusterPodNets:
  - "10.244.0.0/16"
  - "fdad:cafe:244::/112"
clusterSvcNets:
  - "10.245.0.0/16"
  - "fdad:cafe:245::/112"

# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
talosVersion: v1.10.5
# renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
kubernetesVersion: v1.33.2

endpoint: https://k8s.${PRIVATE_DOMAIN2}:6443

additionalApiServerCertSans: &san
  - ${CLUSTER_ENDPOINT_IP}
  - k8s.${PRIVATE_DOMAIN2}
  - 127.0.0.1

additionalMachineCertSans: *san

cniConfig:
  name: none

nodes:
  - hostname: cp01.${PRIVATE_DOMAIN2}
    ipAddress: 192.168.1.201
    installDisk: /dev/nvme2n1
    controlPlane: true
    disableSearchDomain: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "00:1b:21:bc:69:1e"
        dhcp: true
        vip:
          ip: ${CLUSTER_ENDPOINT_IP}
        # vlans:
        #   - vlanId: 10
        #     addresses:
        #       - "192.168.10.201/23"
        #     routes:
        #       - network: 192.168.10.0/23
        #         gateway: 192.168.10.1
        #   - vlanId: 20
        #     addresses:
        #       - "192.168.20.201/24"
        #     routes:
        #       - network: 192.168.20.0/24
        #         gateway: 192.168.20.1
        #   - vlanId: 30
        #     addresses:
        #       - "192.168.30.201/24"
        #     routes:
        #       - network: 192.168.30.0/24
        #         gateway: 192.168.30.1
    nodeLabels:
      topology.kubernetes.io/region: k8s
      topology.kubernetes.io/zone: cp
    schematic:
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/intel-ucode
            - siderolabs/i915
            - siderolabs/intel-ice-firmware
            - siderolabs/uinput
        extraKernelArgs: &intelKernalArgs
          - cpufreq.default_governor=performance
          - intel_iommu=on
          - intel_pstate=disable
          - iommu=pt
          - iommu.passthrough=1
          - i915.enable_guc=3
          - mitigations=off
          - net.ifnames=0
          - sysctl.kernel.kexec_load_disabled=1
          - -selinux

  - hostname: cp02.${PRIVATE_DOMAIN2}
    ipAddress: 192.168.1.202
    installDisk: /dev/nvme2n1
    controlPlane: true
    disableSearchDomain: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "00:1b:21:bc:6f:83"
        dhcp: true
        vip:
          ip: ${CLUSTER_ENDPOINT_IP}
        # vlans:
        #   - vlanId: 10
        #     addresses:
        #       - "192.168.10.202/23"
        #     routes:
        #       - network: 192.168.10.0/23
        #         gateway: 192.168.10.1
        #   - vlanId: 20
        #     addresses:
        #       - "192.168.20.202/24"
        #     routes:
        #       - network: 192.168.20.0/24
        #         gateway: 192.168.20.1
        #   - vlanId: 30
        #     addresses:
        #       - "192.168.30.202/24"
        #     routes:
        #       - network: 192.168.30.0/24
        #         gateway: 192.168.30.1
    nodeLabels:
      topology.kubernetes.io/region: k8s
      topology.kubernetes.io/zone: cp
    schematic:
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/intel-ucode
            - siderolabs/i915
        extraKernelArgs: *intelKernalArgs

  - hostname: cp03.${PRIVATE_DOMAIN2}
    ipAddress: 192.168.1.203
    installDisk: /dev/nvme2n1
    controlPlane: true
    disableSearchDomain: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "00:1b:21:bc:6a:a5"
        dhcp: true
        vip:
          ip: ${CLUSTER_ENDPOINT_IP}
        # vlans:
        #   - vlanId: 10
        #     addresses:
        #       - "192.168.10.203/23"
        #     routes:
        #       - network: 192.168.10.0/23
        #         gateway: 192.168.10.1
        #   - vlanId: 20
        #     addresses:
        #       - "192.168.20.203/24"
        #     routes:
        #       - network: 192.168.20.0/24
        #         gateway: 192.168.20.1
        #   - vlanId: 30
        #     addresses:
        #       - "192.168.30.203/24"
        #     routes:
        #       - network: 192.168.30.0/24
        #         gateway: 192.168.30.1
    nodeLabels:
      topology.kubernetes.io/region: k8s
      topology.kubernetes.io/zone: cp
    schematic:
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/amd-ucode
            - siderolabs/nonfree-kmod-nvidia-production
            - siderolabs/nvidia-container-toolkit-production
            - siderolabs/uinput
        extraKernelArgs:
          - cpufreq.default_governor=performance
          - amd_pstate=active
          - iommu=pt
          - iommu.passthrough=1
          - mitigations=off
          - -selinux
    patches:
      - |-
        - op: add
          path: /machine/kernel
          value:
            modules:
              - name: nvidia
              - name: nvidia_uvm
              - name: nvidia_drm
              - name: nvidia_modeset
              - name: nbd
        - op: add
          path: /machine/sysctls
          value:
            net.core.bpf_jit_harden: 1

  # - hostname: wk01.${PRIVATE_DOMAIN}
  #   ipAddress: 192.168.1.211
  #   installDisk: /dev/vda
  #   controlPlane: false
  #   disableSearchDomain: true
  #   networkInterfaces:
  #     - deviceSelector:
  #         hardwareAddr: "2e:d1:86:5c:91:3f"
  #         driver: virtio_net
  #       dhcp: true
  #       vlans:
  #         - vlanId: 10
  #           addresses:
  #             - "192.168.10.211/23"
  #           routes:
  #             - network: 192.168.10.0/23
  #               gateway: 192.168.10.1
  #         - vlanId: 20
  #           addresses:
  #             - "192.168.20.211/24"
  #           routes:
  #             - network: 192.168.20.0/24
  #               gateway: 192.168.20.1
  #         - vlanId: 30
  #           addresses:
  #             - "192.168.30.211/24"
  #           routes:
  #             - network: 192.168.30.0/24
  #               gateway: 192.168.30.1
  #   nodeLabels:
  #     topology.kubernetes.io/region: k8s
  #     topology.kubernetes.io/zone: wk
  #   schematic:
  #     customization:
  #       systemExtensions:
  #         officialExtensions:
  #           - siderolabs/intel-ucode
  #           - siderolabs/i915
  #           - siderolabs/qemu-guest-agent
  #           - siderolabs/intel-ice-firmware
  #       extraKernelArgs: *intelKernalArgs

controlPlane:
  nodeLabels:
    topology.kubernetes.io/region: *cluster
    topology.kubernetes.io/zone: cp
  patches:
    # Set all disks to no scheduler
    - &noschedulerPatch |-
      machine:
        udev:
          rules:
            # set all disks to `none` scheduler (optimal setting for Ceph and ZFS)
            - SUBSYSTEM=="block", ENV{DEVTYPE}=="disk", ATTR{queue/scheduler}="none"
            # allow GID 44 (video) to use Intel GPU
            - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"
    # Configure containerd
    - &containerdPatch |-
      machine:
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |-
              [plugins."io.containerd.grpc.v1.cri"]
                enable_unprivileged_ports = true
                enable_unprivileged_icmp = true
              [plugins."io.containerd.grpc.v1.cri".containerd]
                discard_unpacked_layers = false
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                discard_unpacked_layers = false

    # Disable search domain everywhere
    - &disableSearchDomainPatch |-
      machine:
        network:
          disableSearchDomain: true

    # Enable cluster discovery
    - &discoveryPatch |-
      cluster:
        discovery:
          registries:
            kubernetes:
              disabled: true
            service:
              disabled: false

    # Enable MutatingAdmissionPolicy
    - |-
      cluster:
        apiServer:
          extraArgs:
            runtime-config: admissionregistration.k8s.io/v1alpha1=true
            feature-gates: MutatingAdmissionPolicy=true

    # Configure kubelet
    - &kubeletPatch |-
      machine:
        kubelet:
          extraArgs:
            feature-gates: GracefulNodeShutdown=true
            rotate-server-certificates: true
          nodeIP:
            validSubnets:
              - 192.168.1.0/24
              - ${PUBLIC_IPV6_PREFIX}:0::/64
          extraConfig:
            maxPods: 150

    # Enable KubePrism
    - &kubePrismPatch |-
      machine:
        features:
          kubePrism:
            enabled: true
            port: 7445

    # Enable logging
    # - &loggingPatch |-
    #   machine:
    #     logging:
    #       destinations:
    #         - endpoint: udp://vector.${PRIVATE_DOMAIN}:6002
    #           format: json_lines

    # Force nameserver
    - &nameserverPatch |-
      machine:
        network:
          nameservers:
            - 192.168.1.1
            - ${PUBLIC_IPV6_PREFIX}::1

    # Configure NFS mount options
    - &nfsPatch |-
      machine:
        files:
          - op: overwrite
            path: /etc/nfsmount.conf
            permissions: 0o644
            content: |
              [ NFSMount_Global_Options ]
              nfsvers=4.1
              hard=True
              noatime=True
              nodiratime=True
              rsize=131072
              wsize=131072
              nconnect=8

    # Configure NTP
    - &ntpPatch |-
      machine:
        time:
          disabled: false
          servers:
            - time.cloudflare.com

    # Static host entries
    - &staticHostEntriesPatch |-
      machine:
        network:
          extraHostEntries:
            - ip: ${CLUSTER_ENDPOINT_IP}
              aliases:
                - k8s.${PRIVATE_DOMAIN2}
            - ip: 192.168.1.1
              aliases:
                - unifi.${PRIVATE_DOMAIN2}
            - ip: 192.168.1.100
              aliases:
                - nas.${PRIVATE_DOMAIN2}
                - s3.${PRIVATE_DOMAIN2}
            - ip: 192.168.11.4
              aliases:
                - vector.${PRIVATE_DOMAIN2}

    # Custom sysctl settings
    - &sysctlPatch |-
      machine:
        sysctls:
          fs.inotify.max_user_watches: 1048576
          fs.inotify.max_user_instances: 8192
          kernel.randomize_va_space: 0
          net.core.netdev_max_backlog: 30000
          net.core.rmem_max: 67108864
          net.core.wmem_max: 67108864
          net.ipv4.tcp_rmem: 4096 87380 33554432
          net.ipv4.tcp_wmem: 4096 65536 33554432
          net.ipv4.tcp_tw_reuse: 1
          net.ipv4.tcp_window_scaling: 1
          net.ipv4.tcp_congestion_control: bbr
          net.ipv4.tcp_mtu_probing: 1
          net.core.default_qdisc: fq
          net.ipv4.tcp_fastopen: 3
          vm.nr_hugepages: 1024
          net.ipv6.conf.all.accept_ra: "2"
          net.ipv6.conf.all.forwarding: "1"

    # Custom Talos installer patch
    - &talosPatch |-
      machine:
        install:
          legacyBIOSSupport: true

    # Tailscale auth
    # - &tailscalePatch |-
    #   machine:
    #     files:
    #       - content: |
    #           TS_AUTHKEY=${SECRET_TS_AUTHKEY}
    #         permissions: 0o644
    #         path: /var/etc/tailscale/auth.env
    #         op: create

    # Mount openebs-hostpath in kubelet
    - &openebsPatch |-
      machine:
        kubelet:
          extraMounts:
            - destination: /var/openebs/local
              type: bind
              source: /var/openebs/local
              options: ["bind", "rshared", "rw"]

    # Cluster configuration
    - |-
      cluster:
        allowSchedulingOnMasters: true
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
            node-cidr-mask-size-ipv4: "24"
            node-cidr-mask-size-ipv6: "120"
        coreDNS:
          disabled: true
        proxy:
          disabled: true
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0
          config:
            apiVersion: kubescheduler.config.k8s.io/v1
            kind: KubeSchedulerConfiguration
            profiles:
              - schedulerName: default-scheduler
                pluginConfig:
                  - name: PodTopologySpread
                    args:
                      defaultingType: List
                      defaultConstraints:
                        - maxSkew: 1
                          topologyKey: kubernetes.io/hostname
                          whenUnsatisfiable: ScheduleAnyway
        network:
          dnsDomain: cluster.local

    # ETCD configuration
    - |-
      cluster:
        etcd:
          extraArgs:
            listen-metrics-urls: http://0.0.0.0:2381
            unsafe-no-fsync: true
          advertisedSubnets:
            - 192.168.1.0/24

    # Disable default API server admission plugins.
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:admin
            allowedKubernetesNamespaces:
              - system-upgrade
          apidCheckExtKeyUsage: true
          diskQuotaSupport: true

    # Enable host dns
    - &hostDnsPatch |-
      machine:
        features:
          hostDNS:
            enabled: false
            resolveMemberNames: true
            forwardKubeDNSToHost: false

    # Add nbd module
    - &nbdModule |-
      machine:
        kernel:
          modules:
            - name: nbd

# worker:
#   nodeLabels:
#     topology.kubernetes.io/region: *cluster
#     topology.kubernetes.io/zone: wk
#   patches:
#     - *containerdPatch
#     - *disableSearchDomainPatch
#     - *discoveryPatch
#     - *kubeletPatch
#     - *kubePrismPatch
#     # - *loggingPatch
#     - *nameserverPatch
#     - *nfsPatch
#     - *ntpPatch
#     - *staticHostEntriesPatch
#     - *sysctlPatch
#     - *talosPatch
#     # - *tailscalePatch
#     - *noschedulerPatch
#     - *openebsPatch
#     - *hostDnsPatch
#     - *nbdModule
